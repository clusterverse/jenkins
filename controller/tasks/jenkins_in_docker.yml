---
## Note: install Jenkins Docker from source (https://github.com/jenkinsci/docker), because the image sets the uid and gid to 1000, which
##  causes irreconcilable conflicts with the host.  See also https://github.com/jenkinsci/docker/issues/112

- name: jenkins Docker build
  block:
#    - name: jenkins Docker | prune old docker images & volumes
#      become: true
#      shell: "docker image prune -f; docker volume prune -f"

    - name: Assert that if host_docker.network.container.cidr is defined (and valid IP), host_docker.network.container.name is also defined (we cannot change the cidr of the default 'bridge' network)
      assert: { that: "host_docker.network.container.name is defined and host_docker.network.container.cidr | ipaddr('network/prefix') | length > 0", fail_msg: "If host_docker.network.container.cidr is defined, host_docker.network.container.name must also be defined" }
      when: "host_docker.network.container.mode=='bridge' and host_docker.network.container.cidr is defined"

    - name: jenkins Docker | Create the Docker network
      become: true
      community.docker.docker_network:
        name: "{{host_docker.network.container.name}}"
        ipam_config: "{{ [{'subnet': host_docker.network.container.cidr}] if host_docker.network.container.cidr is defined else [] }}"
      when: "host_docker.network.container.mode=='bridge' and host_docker.network.container.name is defined"

    - name: jenkins Docker | Create temporary build directory
      become: true
      tempfile:
        state: directory
        suffix: DockerBuildTEMP
      register: tmp_build_dir

    - name: jenkins Docker | get host docker group (stored as getent_group['docker'][1])
      getent:
        database: group
        key: docker

    - name: jenkins Docker | git clone Jenkins docker build repo from github
      become: true
      git:
        repo: "{{jenkins_controller.docker_image.repo}}"
        version: "{{jenkins_controller.docker_image.repo_version}}"
        dest: "{{ tmp_build_dir.path }}"

    - name: jenkins Docker | Get agent facts to get memory CPU for executors calculation
      ansible.builtin.setup:
      delegate_to: "{{ groups['agent'][0] }}"
      delegate_facts: true
      run_once: true
      when: "'agent' in groups"

    - name: jenkins Docker | create JCasC config file
      become: true
      copy:
        content: "{{ _casc_config_plus_numExecutors_plus_resourceRoot_url_plus_agentnodes | to_nice_json }}"       # Note: we cannot use {{ jenkins_controller.casc_config | string | from_yaml | to_nice_yaml(indent=2, width=10000) }} because the string filter templates the multi-line vaulted ssh keys as double-escaped newlines (hence the re-templating, as vars, below)
        dest: "{{jenkins_controller.casc_file.local}}"
        force: true    # remote file will be replaced when contents are different to the existing
        decrypt: true
        owner: "{{ jenkins_uid }}"
        group: "{{ jenkins_gid }}"
      vars:
        _base_casc_config: "{{jenkins_controller.casc_config}}"     # Note: We need to pre-template {{jenkins_controller.casc_config}} so that the vault credentials are templated-out correctly before filtering as json/yaml.
        __num_executors_controller: "{{ (ansible_processor_vcpus * jenkins_controller.jcasc_numExecutorsMultiplier) | round(0,'ceil')|int }}"    # A rough calculator (good for ansible loads) == (Number of vCPUs) * scaling factor
        _casc_config_plus_numExecutors: "{{_base_casc_config | combine({'jenkins': {'numExecutors': __num_executors_controller }}, recursive=true)}}"
        __location_url: "http://{%- if cluster_vars.dns_server is defined and cluster_vars.dns_server != '' -%} {{ansible_hostname | regex_replace('-(?!.*-).*')}}.{{cluster_vars.dns_user_domain | regex_replace('^(.*?)\\.?$','\\1')}} {%- else -%} {{ansible_default_ipv4.address}} {%- endif -%}"
        _casc_config_plus_numExecutors_plus_resourceRoot_url: "{{_casc_config_plus_numExecutors | combine({'unclassified': {'location': {'url': __location_url}}}, recursive=true)}}"
        __num_executors_agent: "{{ 0 if 'agent' not in groups  else  (hostvars[groups['agent'][0]]['ansible_processor_vcpus'] * jenkins_agent.numExecutorsMultiplier) | default(0) | round(0,'ceil')|int }}"    # A rough calculator (good for ansible loads) == (Number of vCPUs) * scaling factor
        __agentnodes: "{{ [] if 'agent' not in groups  else  groups['agent'] | json_query(\"[].{permanent: {labelString: `agent`, name: @, numExecutors: `\" + __num_executors_agent|string + \"`, remoteFS: `/home/jenkins`, launcher: {inbound: {workDirSettings: {disabled: `false`, failIfWorkDirIsMissing: `true`, internalDir: `remoting`}}}}}\") }}"
        _casc_config_plus_numExecutors_plus_resourceRoot_url_plus_agentnodes: "{{_casc_config_plus_numExecutors_plus_resourceRoot_url | combine({'jenkins': {'nodes': __agentnodes}}, recursive=true)}}"
      register: r__copy_jcasc

    - name: jenkins Docker | augment the dockerfile
      become: true
      blockinfile:
        path: "{{ tmp_build_dir.path }}{{jenkins_controller.docker_image.repo_dockerfile_path}}"
        block: |
          USER root

          # Install the dependencies for the Docker CLI (so we can run Docker builds in the container)
          RUN apt-get update \
          && apt-get install -y git vim sudo procps python3-pip \
          && apt-get install -y --no-install-recommends apt-transport-https ca-certificates curl gnupg-agent software-properties-common \
          && install -m 0755 -d /etc/apt/keyrings \
          && curl -fsSL https://download.docker.com/linux/debian/gpg -o /etc/apt/keyrings/docker.asc \
          && chmod a+r /etc/apt/keyrings/docker.asc \
          && echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/debian $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null \
          && apt-get update && apt-get install -y --no-install-recommends docker-ce-cli

          # Create a 'docker' group to mirror the docker group on the host. Note: Cannot `usermod -a -G docker jenkins` here.  Need to start the container with --group-add docker (in Ansible, add to the 'groups')
          RUN ((getent group docker && groupmod -g {{host_docker_gid}} docker) || addgroup docker --gid {{host_docker_gid}}) && usermod -a -G docker jenkins
          
          # Extract jenkins-cli.jar from the war file
          RUN unzip -j /usr/share/jenkins/jenkins.war WEB-INF/lib/cli-*.jar -d /usr/local/bin && mv /usr/local/bin/cli-*.jar /usr/local/bin/jenkins-cli.jar
          
          # Create an 'update_plugins.groovy' file that we can use to update all the plugins
          RUN echo "import jenkins.model.*\n\ndef pluginManager = Jenkins.instance.pluginManager\n\npluginManager.doCheckUpdatesServer()\n\ndef plugins = pluginManager.plugins.findAll { it -> it.hasUpdate() }.collect { it -> it.getShortName() }\n\nif (plugins) {\n    pluginManager.install(plugins, false).each { it -> it.get() }\n    Jenkins.instance.safeRestart()\n}" > /usr/local/bin/update_plugins.groovy

          USER ${user}

          # Options for jenkins-plugin-cli: https://github.com/jenkinsci/plugin-installation-manager-tool.    # NOTE: This used to have problems (not tested recently) downloading plugins when built in GCP for some reason (gives "Unable to resolve plugin URL...").
          RUN /bin/jenkins-plugin-cli --verbose --plugins {{ jenkins_controller.plugins | join(' ') }}
          ## This is the legacy plugin installer. This was removed in 9b54caaf578b872fe3a89c3d83a69e2b7893ca5a - 26/06/2022
          ## RUN /usr/local/bin/install-plugins.sh {{ jenkins_controller.plugins | join(' ') }}
      vars:
        host_docker_gid: "{{getent_group['docker'][1]}}"

    - name: jenkins Docker | remove the validation of the SHA of the war file in the Dockerfile with the calculated SHA of the war file (because we're specifying the war file ourselves)
      become: true
      ansible.builtin.replace:
        path: "{{ tmp_build_dir.path }}{{jenkins_controller.docker_image.repo_dockerfile_path}}"
        regexp: '(^\s*)&&.*?sha256sum.*?(\s*\\)?$'
        replace: '\g<1>&& /bin/true\g<2>'
      register: r__lineinfile
      failed_when: not r__lineinfile.changed

    - name: jenkins Docker | debug r__lineinfile
      debug: msg={{r__lineinfile}}

    - name: jenkins Docker | Get the Jenkins release maven-metadata
      uri:
        url: "https://repo.jenkins-ci.org/public/org/jenkins-ci/main/jenkins-war/maven-metadata.xml"
        return_content: true
        status_code: 200
      register: r__uri

    - name: jenkins Docker | Extract the xml from the Jenkins release metadata
      community.general.xml:
        xmlstring : "{{r__uri.content}}"
        content: "text"
        xpath: "/metadata/versioning/versions/version"
      delegate_to: localhost
      run_once: true
      register: r__xml

    - set_fact:
        jenkins_war_version: "{%-if jenkins_controller.docker_image.war_version == 'latest-lts' -%}{{_latest_jenkins_version_lts}}{%- elif jenkins_controller.docker_image.war_version == 'latest' -%}{{_latest_jenkins_version}}{%- else -%}{{jenkins_controller.docker_image.war_version}}{%- endif -%}"
      vars:
        _latest_jenkins_version: "{{r__xml.matches | json_query(\"[].version\") | semver_sort | last }}"
        _latest_jenkins_version_lts: "{{r__xml.matches | json_query(\"[].version\") | map('regex_search', '^[0-9]+\\.[0-9]+\\.[0-9]+$') | list | json_query(\"[]\") | semver_sort | last }}"

    - name: jenkins Docker | Build the jenkins Docker image
      become: true
      community.docker.docker_image:
        source: build
        build:
          dockerfile: "{{ tmp_build_dir.path }}{{jenkins_controller.docker_image.repo_dockerfile_path}}"
          args:
            uid: "{{ jenkins_uid }}"
            gid: "{{ jenkins_gid }}"
            TARGETARCH: "{{ 'amd64' if ansible_architecture == 'x86_64' else 'arm64' if ansible_architecture == 'aarch64' else ansible_architecture }}"
            JENKINS_VERSION: "{{ jenkins_war_version }}"
            JENKINS_HOME: "{{jenkins_home_dir}}"
            RELEASE_LINE: "{{ 'war-stable' if jenkins_controller.docker_image.war_version == 'latest-lts' else 'war' }}"
            PLUGIN_CLI_URL: "{{ lookup('url', 'https://api.github.com/repos/jenkinsci/plugin-installation-manager-tool/releases/' + jenkins_controller.docker_image.plugin_cli_version) | from_json | json_query(\"assets[?ends_with(browser_download_url, '.jar')].browser_download_url | [0]\") }}"
          network: host
          pull: true
          nocache: "{{ 'yes' if rebuild_docker_image is defined and rebuild_docker_image|bool else 'no' }}"       # Setting this to 'yes' will cause a rebuild every time, forcing a new image to be built, even if no changes have been made to the Dockerfile.
          rm: true
          path: "{{ tmp_build_dir.path }}"
        force_source: true
        name: "jenkins_controller:{{ jenkins_war_version }}"
      register: r__docker_image

    - name: jenkins Docker | Create and run the container without any config, then update the plugins, then run *with* the config
      block:
        - name: jenkins_docker_conf
          debug: msg={{jenkins_docker_conf}}

        - name: jenkins Docker | Create and run the initial Jenkins Docker container
          become: true
          community.docker.docker_container: "{{jenkins_docker_conf}}"
          register: r__docker_container

        - name: jenkins Docker | Wait for Jenkins API to become available
          uri: { url: "http://127.0.0.1:80/api", status_code: 200 }
          register: r__uri
          until: r__uri.status == 200
          retries: 60
          delay: 1

        - name: jenkins Docker | Update twice.  First time for the current plugins, second time for the any plugins that were held back because the first plugins were disabled
          block:
            - name: jenkins Docker | update all the builtin plugins (docker exec)
              become: true
              community.docker.docker_container_exec:
                container: "{{ r__docker_container.container.Name | regex_replace('^/')}}"
                command: "/bin/bash -c \"java -jar /usr/local/bin/jenkins-cli.jar -s http://localhost:8080 -auth {{jenkins_admin_username}}:{{jenkins_admin_password}} groovy = < /usr/local/bin/update_plugins.groovy\""
                chdir: "/home/{{jenkins_username}}"
              register: r__docker_container_exec

            - name: jenkins Docker | Wait for Jenkins API to become available
              uri: { url: "http://127.0.0.1:80/api", status_code: 200 }
              register: r__uri
              until: r__uri.status == 200
              retries: 60
              delay: 1

            - name: jenkins Docker | update all the builtin plugins again (docker exec)
              become: true
              community.docker.docker_container_exec:
                container: "{{ r__docker_container.container.Name | regex_replace('^/')}}"
                command: "/bin/bash -c \"java -jar /usr/local/bin/jenkins-cli.jar -s http://localhost:8080 -auth {{jenkins_admin_username}}:{{jenkins_admin_password}} groovy = < /usr/local/bin/update_plugins.groovy\""
                chdir: "/home/{{jenkins_username}}"
              register: r__docker_container_exec

            - name: jenkins Docker | Wait for Jenkins API to become available
              uri: { url: "http://127.0.0.1:80/api", status_code: 200 }
              register: r__uri
              until: r__uri.status == 200
              retries: 60
              delay: 1

        - name: jenkins Docker | Recreate and run the jenkins Docker container
          become: true
          community.docker.docker_container: "{{ jenkins_docker_conf | combine(extra_jenkins_docker_conf) }}"
          vars:
            extra_jenkins_docker_conf:
              env:
                CASC_JENKINS_CONFIG: "{{ jenkins_controller.casc_file.remote | dirname }}"
              mounts:
                - {"target": "{{jenkins_home_dir}}", "source": "jenkins_home", "type": "volume"}
                - {"target": "/var/run/docker.sock", "source": "/var/run/docker.sock", "type": "bind"}
                - {"target": "{{jenkins_controller.casc_file.remote}}", "source": "{{jenkins_controller.casc_file.local}}", "type": "bind"}

        - name: jenkins Docker | Wait for Jenkins API to become available
          uri: { url: "http://127.0.0.1:80/api", status_code: 200 }
          register: r__uri
          until: r__uri.status == 200
          retries: 60
          delay: 1

      vars:
        jenkins_docker_conf:
          cleanup: false
          detach: true
          name: "jenkins_controller"
          user: "{{jenkins_uid}}:{{jenkins_gid}}"
          groups: ["docker"]
          hostname: "docker--{{inventory_hostname}}"
          image: "{{r__docker_image.image.Id}}"
          image_name_mismatch: ignore
          recreate: false        # Setting this to 'true' forces reprovisioning of the container even if the image has not changed
          state: started
          restart: "{%- if r__copy_jcasc.changed -%}true{%-else-%}false{%- endif -%}"
          restart_policy: "always"
          network_mode: "{{ host_docker.network.container.mode | default('host') }}"
          networks_cli_compatible: true
          networks: "{{ [{'name': host_docker.network.container.name}] if host_docker.network.container.mode == 'bridge' and host_docker.network.container.name is defined else [] | to_json }}"
          ports: ["80:8080", "443:8443", "50000:50000"]
          env:
            # NOTE: EXCLUDE_SESSION_ID and DISABLE_CSRF_PROTECTION are needed for Jenkins Job Builder, which doesn't currently support either Session IDs or CSRF crumb (https://storyboard.openstack.org/#!/story/2006489)
            # NOTE: -Dpermissive-script-security.enabled=true is there to allow scripts to work without having to manually approve them all.  Also need the permissive-script-security plugin.  There is also a 'no_security' option that turns off all logging.
            JAVA_OPTS: "-XX:+ExplicitGCInvokesConcurrent -Djenkins.install.runSetupWizard=false -Dhudson.security.csrf.DefaultCrumbIssuer.EXCLUDE_SESSION_ID=true -Dhudson.security.csrf.GlobalCrumbIssuerConfiguration.DISABLE_CSRF_PROTECTION=true -Dpermissive-script-security.enabled=true -Dorg.jenkinsci.plugins.durabletask.BourneShellScript.LAUNCH_DIAGNOSTICS=true -Dhudson.model.ParametersAction.keepUndefinedParameters=false"
  #          JENKINS_OPTS: "--httpsPort=8443" --httpsKeyStore=path/to/keystore --httpsKeyStorePassword=keystorePassword
            JENKINS_HOME: "{{jenkins_home_dir}}"
          mounts:
            - {"target": "{{jenkins_home_dir}}", "source": "jenkins_home", "type": "volume"}
            - {"target": "/var/run/docker.sock", "source": "/var/run/docker.sock", "type": "bind"}


    - name: jenkins Docker | truncate JCasC config file.  Do not delete, as it is bind-mounted, so needs to exist if the VM restarts.  Cannot Ansible 'copy' to an empty string, as this changes the inode (which is what is really bind-mounted)
      become: true
      shell: "truncate -s0 {{jenkins_controller.casc_file.local}}"

    - name: jenkins Docker | Remove temporary build directory
      become: true
      file:
        path: "{{ tmp_build_dir.path }}"
        state: absent
